wandb:
  project: "SFT-HPO"
  display_name: "qwen2.5-python-coder"
dataset: "newfacade/LeetCodeDataset"
model_name: "Qwen/Qwen2.5-7B-Instruct"
ckpt_name: "python_coder_checkpoint"
cot_gen_model: "gpt-5-mini"

sft:
  num_epochs: 3
  batch_size: 16
  grad_accum_steps: 2
  learning_rate: 2e-5
  warmup_ratio: 0.05

lora:
  rank: 8
  alpha: 32
  dropout: 0.05
  target: ["q_proj", "v_proj", "o_proj"]

generation:
  max_new_tokens: 2048
  temperature: 0.5
  top_p: 0.95